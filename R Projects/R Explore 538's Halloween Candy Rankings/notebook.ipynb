{"cells":[{"metadata":{"dc":{"key":"4"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 1. Importing packages and data\n<p><img src=\"https://assets.datacamp.com/production/project_458/img/candy.jpg\" alt=\"Bowl of halloween candy\"></p>\n<p>Every year around Halloween it seems like everyone has candy on the brain! There's a great dataset from <a href=\"https://fivethirtyeight.com/\">FiveThirtyEight</a> that includes all sorts of different information about different kinds of candy. For example, is a candy chocolaty? Does it have nougat? How does its cost compare to other candies? How many people prefer one candy over another?</p>\n<p>We'll take a whirlwind tour of this dataset and wrap up by trying linear and logistic regression techniques out on it!</p>\n<p>First things first, let's get our packages and data loaded up and inspect the data to see exactly what we're dealing with.</p>"},{"metadata":{"dc":{"key":"4"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":"# Load all the packages\nlibrary('dplyr')\nlibrary('tidyr')\nlibrary('ggplot2')\nlibrary('broom')\nlibrary('corrplot')\nlibrary('fivethirtyeight')\n# Load the candy_rankings dataset from the fivethirtyeight package\ndata(candy_rankings)\n\n# Take a glimpse() at the dataset\nglimpse(candy_rankings)","execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"11"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 2. Explore the distributions of categorical variables\n<p>Let's get started by looking at the distributions of each binary categorical variable. There are quite a few of them - we'll have to do some data wrangling to get them in shape for plotting. </p>\n<p>We can get a sense of the proportion of <code>TRUE</code>s and <code>FALSE</code>s in each column by using the <code>gather()</code> function to get the dataset to look like this:</p>\n<pre><code>  competitorname sugarpercent pricepercent winpercent feature   value\n  &lt;chr&gt;                 &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;     &lt;lgl&gt;\n1 100 Grand             0.732        0.860       67.0 chocolate TRUE \n2 3 Musketeers          0.604        0.511       67.6 chocolate TRUE \n3 One dime              0.011        0.116       32.3 chocolate FALSE\n</code></pre>\n<p>Then we can make a bar chart showing the number of <code>TRUE</code>s and <code>FALSE</code>s for each type of candy (<code>feature</code>).</p>\n<p>Note: Development on <code>gather()</code> is complete, but it is still taught in several DataCamp courses. We will continue to use it here.</p>"},{"metadata":{"dc":{"key":"11"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":"# Gather the categorical variables to make them easier to plot\ncandy_rankings_long <- gather(candy_rankings,\"feature\", \"value\",chocolate:pluribus)\n\n# Make a bar plot showing the distribution of each variable\nggplot(candy_rankings_long,aes(value))+\n geom_bar()+\n facet_wrap(~feature)","execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"18"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 3. Taking a look at pricepercent\n<p>Next, we'll look at the <code>pricepercent</code> variable. This variable records the percentile rank of the candy's price against all the other candies in the dataset. Let's see which is the most expensive and which is the least expensive by making a lollipop chart. One of the most interesting aspects of this chart is that a lot of the candies share the same ranking, so it looks like quite a few of them are the same price.</p>"},{"metadata":{"dc":{"key":"18"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":"# Make a lollipop chart of pricepercent\nggplot(candy_rankings,aes(x=reorder(competitorname,pricepercent),y=pricepercent))+\n geom_segment(aes(xend=reorder(competitorname, pricepercent), yend = 0))+\n geom_point()+\n coord_flip()","execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"25"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 4. Exploring winpercent (part i)\n<p>Moving on, we'll take a look at another numerical variable in the dataset: <code>winpercent</code>. This variable is the percentage of people who prefer this candy over another randomly chosen candy from the dataset. </p>\n<p>We'll start with a histogram! The distribution of rankings looks symmetrical and seems to center on about 45%! </p>"},{"metadata":{"dc":{"key":"25"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":"# Plot a histogram of winpercent\nggplot(candy_rankings,aes(winpercent))+\n geom_histogram()\n","execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"32"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 5. Exploring winpercent (part ii)\n<p>Now that we've looked at the histogram, let's make another lollipop chart to visualize the rankings. It looks like Reese's Peanut Butter Cups are the all time favorite out of this set of candies!</p>"},{"metadata":{"dc":{"key":"32"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":"# Make a lollipop chart of winpercent\n\nggplot(candy_rankings,aes(x=reorder(competitorname,winpercent),y=winpercent))+\n geom_segment(aes(xend=reorder(competitorname, winpercent), yend = 0))+\n geom_point()+\n coord_flip()","execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"39"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 6. Exploring the correlation structure\n<p>Now that we've explored the dataset one variable at a time, we'll see how the variables interact with one another. This is important as we get ready to model the data because it will give us some intuition about which variables might be useful as explanatory variables. </p>\n<p>We'll use the <code>corrplot</code> package to plot a correlation matrix. Taking a look at this plot, it looks like chocolaty candies are almost never fruity. I can certainly see why that's the case! This also allows us to check for possible <a href=\"https://en.wikipedia.org/wiki/Multicollinearity\">multicollinearity</a>, which can be a problem for regression modeling. It looks like we're good though!</p>"},{"metadata":{"dc":{"key":"39"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":"# Plot the correlation matrix\ncandy_rankings%>%\n select(-competitorname)%>%\n cor()%>%\n corrplot()","execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"46"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 7. Fitting a linear model of winpercent\n<p><img src=\"https://assets.datacamp.com/production/project_458/img/snickers.jpg\" style=\"float: left;margin:5px 20px 5px 1px;max-width: 33%\"></p>\n<p>Let's dive into the deep end of modeling by creating a linear model of <code>winpercent</code> using all the other variables except <code>competitorname</code>. </p>\n<p>Because <code>competitorname</code> is a categorical variable with a unique value in every row, it is mathematically impossible to fit a linear model if it is included. Moreover, this variable doesn't add any information that the model could use because the names do not relate to any of the candies' attributes.</p>\n<p>Let's fit the model! Then we can dive into exploring it. Maybe this will give us an idea of why people tend to prefer one candy over another!</p>"},{"metadata":{"dc":{"key":"46"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":"# Fit a linear model of winpercent explained by all variables \n# except competitorname\nwin_mod <- lm(winpercent~.-competitorname,data=candy_rankings)","execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"53"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 8. Evaluating the linear model\n<p>Let's see how we did! We'll take a look at the results of our linear model and run some basic diagnostics to make sure the output is reliable.</p>\n<p>Taking a look at the coefficients, we can make some conclusions about the factors that cause people to choose one candy over another. For example, it looks like people who took this survey really like peanut butter! There are a few other significant coefficients. Which ones are these?</p>"},{"metadata":{"dc":{"key":"53"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":"# Take a look at the summary\nsummary(win_mod)\n# Plot the residuals vs the fitted values\naugment(win_mod)%>%\n ggplot(aes(x=.fitted,y=.resid))+\n geom_point()+\n geom_hline(yintercept=0)","execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"60"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 9. Fit a logistic regression model of chocolate\n<p><img src=\"https://assets.datacamp.com/production/project_458/img/chocolate.jpg\" style=\"float: left;margin:5px 20px 5px 1px;max-width: 33%\"></p>\n<p>Now let's try out logistic regression! We'll be trying to predict if a candy is chocolaty or not based on all the other features in the dataset. </p>\n<p>A logistic regression is a great choice for this particular modeling task because the variable we're trying to predict is either <code>TRUE</code> or <code>FALSE</code>. The logistic regression model will output a probability that we can use to make our decision. </p>\n<p>This model outputs a warning because a few of the features (like <code>crispedricewafer</code>) are only ever true when a candy is chocolate. This means that we cannot draw conclusions from the coefficients, but we can still use the model to make predictions!</p>"},{"metadata":{"dc":{"key":"60"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":"# Fit a glm() of chocolate\nchoc_mod <- glm(chocolate~.-competitorname,data=candy_rankings,family='binomial')","execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"67"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 10. Evaluate the logistic regression model\n<p>Let's take our logistic regression model out for a spin! We'll start by creating a data frame of predictions we can compare to the actual values. Then we'll evaluate the model by making a confusion matrix and calculating the accuracy.</p>\n<p>Looking at the summary, it looks like most of the coefficients aren't statistically significant. In this case, that's okay because we're not trying to draw any conclusions about the relationships between the predictor variables and the response. We're only trying to make accurate predictions and, taking a look at our confusion matrix, it seems like we did a pretty good job!</p>"},{"metadata":{"dc":{"key":"67"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":"# Print the summary\nsummary(choc_mod)\n# Make a data frame of predictions\npreds <- augment(choc_mod,type.predict='response')%>%\n         mutate(prediction=.fitted>0.5)\n\n# Create the confusion matrix\nconf_mat <- preds%>%\n     select(chocolate,prediction)%>%\n     table()\n\n# Calculate the accuracy\naccuracy <- sum(diag(conf_mat))/sum(conf_mat)\naccuracy","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"3.5.3"}},"nbformat":4,"nbformat_minor":2}